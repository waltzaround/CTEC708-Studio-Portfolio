<!DOCTYPE html>
<!-- Hello stranger! You have stumbled on some HTML and some CSS.  (/^▽^)/  (/^▽^)/  (/^▽^)/  

Originally forked the initial code from http://bettermotherfuckingwebsite.com/ and made it better with nice material design elements and whatnot.

Inspired by Jacky Lee's website http://jackylee.co/ - Decided to take things one step further after he gave an interesting talk at my university

Intro screen 

  ooooooo  oooo     oooo  ooooooo8    
o888   888o 8888o   888 o888    88      
888     888 88 888o8 88 888    oooo     
888o   o888 88  888  88 888o    88     
  88ooo88  o88o  8  o88o 888ooo888    
                                           
ooooo ooooo ooooooooooo oooo     oooo ooooo       
 888   888  88  888  88  8888o   888   888        
 888ooo888      888      88 888o8 88   888        
 888   888      888      88  888  88   888      o 
o888o o888o    o888o    o88o  8  o88o o888ooooo88 


  -->
  <html lang="en">
    <head>
      <meta charset="utf-8">

      <meta name="viewport" content="width=device-width, initial-scale=1">
      <title>Walter Lim</title> <!-- OMG A TITLE -->
      <link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'> <!-- OMG AN AWESOME FREE FONT WE CAN DOWNLOAD FROM GOOGLE :D :D :D. Seriously though, Google Fonts is awesome. -->
      <link href="css/style.css" rel="stylesheet" type="text/css"> <!-- Link to CSS so the website looks pretty 
    ╰(✧∇✧╰)
  -->
    </head>

    <body>
        <h1>the matter project</h1>

        <a id="github" href="https://github.com/waltzaround/CTEC708-VR-Project">View the repository here</a>
        <br><br>
        <a id="aut" href="https://trello.com/b/lQ19QmZj/matter">View project tracking here</a>
        <br><br>  
        <a id="tumblr" href="http://idesignmanythings.tumblr.com/tagged/studio">View blog content here</a>
        <br><br>
        <p>The Matter project is an attempt to explore the usability of virtual reality systems, through the use of new hardware, and software development tools. This will be accomplished through the development of a gestural user interface where there are no physical buttons or tactile interfaces. We attempt to explore how users will react to gestural controls when provided with the ability to create music with gestures.</p>

        <p>The project is influenced by research carried out at the Interactive Systems and User Experience Lab (ISUE) by Jared N. Bott where a “collaborative music creation tool”(Bott, Crowley, and LaViola, 2009) was developed in 2009. The project utilised the Nintendo Wii game console and controllers as a hardware platform. As a team, we saw an opportunity to develop the concept of collaborating with gestural controls further using newer technologies like the leap motion sensor and the Oculus Rift head mounted display. We believe that research into collaborative music generation will be an effective method to test out several hypotheses concerning our curiosities around virtual reality UX (User Experience). How will users generate notes without a tactile interface? How will users react to the lack of a tactile interface, let alone the introduction of depth to user interfaces? How will the transition from a flat screen to an immersive space impact users? We seek to answer these questions.</p>

        <p>Matter is also heavily influenced by work carried out at Waseda University in 2008 where “an anthropomorphic flutist robot”(Petersen, Solis, and Takanishi, 2008) has been developed to “realize a better understanding of interaction between musicians and musical performance”(Petersen et al., 2008). The project explored the notion of how compatible robot musicians would be performing alongside humans during performances. We perceived this as particularly notable as we saw music as a novel control interface. We see it as novel as it has remained relatively unexplored specifically within the domain of virtual reality UX.</p>

        <p>In terms of roles and responsibilities, as team lead I am currently responsible for project management, ensuring code integration and design processes occur smoothly, and ensuring the project runs to completion within the allotted timeframe.</p>
        <p>I have failed spectacularly so far.</p>
        <p>The lack of a cohesive vision hampered efforts to accelerate development as every team member had different ideas, and desire to take the project towards a separate tangent. This was only rectified towards the end of April where concepts were locked down and progress accelerated. Refer to commit logs for evidence of progress.</p>
        <p>My lack of research and due diligence was made evident when selecting programming tools, and software development kits (SDKs). Due to a lack of testing we have wasted a quarter of our potential development time exploring, and attempting to find workarounds to tools that were incompatible with our requirements. SDKs that provide insufficient tracking data (Kinect) and obsolete plugins (LiveOSC) drained valuable time that could have been better allocated to other development, or design tasks.  Bad judgement calls were made due to a lack of research, and scoping.</p>

        <p>Bott, J. N., Crowley, J. G., and LaViola, J. J. (2009). One Man Band: A 3D Gestural Interface for Collaborative Music Creation. In IEEE Virtual Reality Conference, 2009. VR 2009 (pp. 273–274). http://doi.org/10.1109/VR.2009.4811051<br><br>Petersen, K., Solis, J., & Takanishi, A. (2008). Toward enabling a natural interaction between human musicians and musical performance robots: Implementation of a real-time gestural interface. In The 17th IEEE International Symposium on Robot and Human Interactive Communication, 2008. RO-MAN 2008 (pp. 340–345). http://doi.org/10.1109/ROMAN.2008.4600689</p>



        


    </body>




 </html>